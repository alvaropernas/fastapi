# Concurrencia y  asincron√≠a / await

Detalles sobre la sintaxis `async def` para *path operation functions* y alg√∫n antecedente sobre c√≥digo as√≠ncrono, concurrencia y paralelismo.

## Tienes prisa?

<abbr title="too long; didn't read"><strong>TL;DR:</strong></abbr>

Si est√°s utilizando bibliotecas de terceros que te dicen que las llames con `await`, del tipo:

```Python
results = await some_library()
```

Despu√©s, declara tus *path operation functions* con `async def` de la siguiente manera:

```Python hl_lines="2"
@app.get('/')
async def read_results():
    results = await some_library()
    return results
```

!!! nota
    Solo puedes usar `await` dentro de funciones creadas con` async def`.

---

Si est√°s utilizando una biblioteca de terceros que se comunica con algo (una base de datos, una API, el sistema de ficheros, etc.) y no tienes soporte para `await` (este es el caso para la mayor√≠a de las librer√≠as de bases de datos), declara tus *path operation functions* de forma habitual, con solo `def`, de la siguiente manera:

```Python hl_lines="2"
@app.get('/')
def results():
    results = some_library()
    return results
```

---

Si tu aplicaci√≥n (de alguna manera) no tiene que comunicarse con nada m√°s y en consecuencia esperar a que responda, usa `async def`.

---

Si simplemente no lo sabes, usa el `def` normal.

---

**Nota**: puedes mezclar `def` y` async def` en tus *path operation functions* tanto como lo necesites y definir cada una utilizando la mejor opci√≥n para ti. FastAPI har√° lo correcto con ellos.

De todos modos, en cualquiera de los casos anteriores, FastAPI seguir√° funcionando de forma as√≠ncrona y ser√° extremadamente r√°pido.

Pero siguiendo los pasos anteriores, FastAPI podr√° hacer algunas optimizaciones de rendimiento.

## Detalles T√©cnicos

Las versiones modernas de Python tienen soporte para **"c√≥digo as√≠ncrono"** usando algo llamado **"coroutines"**, usando la sintaxis **`async` y` await`**.

Veamos esa frase por partes en las secciones siguientes, a continuaci√≥n:

* **C√≥digo As√≠ncrono**
* **`async` y `await`**
* **Coroutines**

## C√≥digo As√≠ncrono

El c√≥digo as√≠ncrono s√≥lo significa que el lenguaje üí¨ tiene una manera de decirle al sistema / programa ü§ñ que en alg√∫n momento del c√≥digo ü§ñ tendr√° que esperar a que *algo m√°s*  termine en otro sitio. Digamos que ese *algo m√°s* se llama, por ejemplo, "archivo lento" üìù.

Durante ese tiempo, el sistema puede hacer otras cosas, mientras "archivo lento" termina.

Entonces el sistema / programa ü§ñ volver√° cada vez que pueda, sea porque est√° esperando otra vez, porque ü§ñ ha terminado todo el trabajo que ten√≠a en ese momento. Y ü§ñ ver√° si alguna de las tareas por las que estaba esperando han terminado, haciendo lo que ten√≠an que hacer.

Luego, ü§ñ coger√° la primera tarea finalizada (digamos, nuestro "archivo lento" üìù) y continuar√° con lo que ten√≠a que hacer con esa tarea.

Esa "espera de otra cosa" normalmente se refiere a operaciones <abbr title = "Input and Output">I/O</abbr> que son relativamente "lentas" (en relaci√≥n a la velocidad del procesador y memoria RAM), como por ejemplo esperar por:

* los datos de cliente que se env√≠an a trav√©s de la red
* los datos enviados por tu programa para ser recibidos por el cliente a trav√©s de la red
* el contenido de un archivo en  disco para ser le√≠do por el sistema y entregado al programa
* los contenidos que tu programa  da al sistema para ser escritos en  disco
* una operaci√≥n relacionada con una API remota
* una operaci√≥n de base de datos
* el retorno de resultados de una consulta de base de datos 
* etc.

Como el tiempo de ejecuci√≥n se consume principalmente al esperar a operaciones de <abbr title = "Input and Output">I/O</abbr>, las llaman operaciones "I/O bound".

Se llama "as√≠ncrono" porque el sistema / programa no tiene que estar "sincronizado" con la tarea lenta, esperando el momento exacto en que finaliza la tarea, sin hacer nada, para poder recoger el resultado de la tarea y continuar el trabajo.

En lugar de eso, al ser un sistema "as√≠ncrono", una vez finalizada, la tarea puede esperar un poco en la cola (algunos microsegundos) para que la computadora / programa termine lo que estaba haciendo, y luego vuelva para recoger los resultados y seguir trabajando con ellos.

Por "s√≠ncrono" (contrario a "as√≠ncrono") tambi√©n se usa habitualmente el t√©rmino "secuencial", porque el sistema / programa sigue todos los pasos secuencialmente antes de cambiar a una tarea diferente, incluso si esos pasos implican esperas.

### Concurrencia y Hamburguesas

El concepto  de c√≥digo **as√≠ncrono** descrito anteriormente a veces tambi√©n se llama **"concurrencia"**. Es diferente del **"paralelismo"**.

**Concurrencia** y **paralelismo** ambos se relacionan con "cosas diferentes que suceden m√°s o menos al mismo tiempo".

Pero los detalles entre *concurrencia* y *paralelismo* son bastante diferentes.

Para entender las diferencias, imagina la siguiente historia sobre hamburguesas:

### Hamburguesas Concurrentes

Vas con tu pareja a pedir comida r√°pida, haces cola mientras el cajero recoge los pedidos de las personas de delante tuyo.

Llega tu turno, haces tu pedido de 2 hamburguesas impresionantes para tu pareja y para ti.

Pagas.

El cajero le dice algo al chico de la cocina para que sepa que tiene que preparar tus hamburguesas (a pesar de que actualmente est√° preparando las de los clientes anteriores).

El cajero te da el n√∫mero de tu turno.

Mientras esperas, vas con tu pareja y eliges una mesa, se sientan y hablan durante un rato largo (ya que las hamburguesas son muy impresionantes y necesitan un rato para prepararse).

Mientras est√°s sentado en la mesa con tu pareja, esperando las hamburguesas, puedes disfrutar ese tiempo admirando lo incre√≠ble, guap@ e inteligente que es tu pareja.

Mientras esperas y hablas con tu pareja, de vez en cuando, verificas el n√∫mero del mostrador para ver si ya es tu turno.

Al final, en alg√∫n momento, llega tu turno. Vas al mostrador, coges tus hamburguesas y vuelves a la mesa.

T√∫ y tu pareja se comen las hamburguesas y se divierten.

---

Imagina que eres el sistema / programa en esa historia.

Mientras est√°s en la cola, est√°s quieto, esperando tu turno, sin hacer nada muy "productivo". Pero la l√≠nea va r√°pida porque el cajero solo recoge los pedidos, as√≠ que est√° bien.

Luego, cuando llega tu turno, haces un trabajo "productivo" real, procesas el men√∫, decides lo que quieres, lo que quiere tu pareja, pagas, verificas que das la factura o tarjeta correctas, verificas que te cobren correctamente, que el pedido tiene los art√≠culos correctos, etc.

Pero entonces, aunque a√∫n no tienes tus hamburguesas, el trabajo hecho con el cajero est√° "en pausa", porque debes esperar a que tus hamburguesas est√©n listas.

Pero a medida que te alejas del mostrador y te sientas en la mesa con un n√∫mero para tu turno, puedes cambiar tu atenci√≥n a tu pareja y "trabajar" en eso. Entonces nuevamente est√°s haciendo algo muy "productivo", como coquetear con tu pareja.

Despu√©s, el cajero dice "He terminado de hacer las hamburguesas" poniendo tu n√∫mero en la pantalla del mostrador, pero no saltas como un loco al momento cuando el n√∫mero que se muestra es el tuyo. Sabes que nadie robar√° tus hamburguesas porque tienes el n√∫mero de tu turno y ellos tienen el suyo.

As√≠ que esperas a que tu pareja termine la historia (termina el trabajo actual / tarea actual que se est√° procesando), sonr√≠es gentilmente y le dices que vas por las hamburguesas.

Luego vas al mostrador, a la tarea inicial que ya est√° terminada, recoges las hamburguesas, les dices gracias y las llevas a la mesa. Eso termina esa fase / tarea de interacci√≥n con el mostrador. Eso a su vez, crea una nueva tarea, "comer hamburguesas", pero la anterior de "conseguir hamburguesas" est√° terminada.


### Hamburguesas Paralelas

Vas con tu pareja para obtener comida r√°pida paralela.

Haces la cola mientras varios cajeros (digamos 8) toman los pedidos de las personas que est√°n delante de ti.

Todos los que est√°n antes de ti est√°n esperando que sus hamburguesas est√©n listas antes de dejar el mostrador porque cada uno de los 8 cajeros prepara la hamburguesa de inmediato antes de recibir el siguiente pedido.

Entonces finalmente es tu turno, haces tu pedido de 2 hamburguesas impresionantes para tu pareja y para ti.

Pagas.

El cajero va a la cocina.

Esperas, parado frente al mostrador, para que nadie m√°s recoja tus hamburguesas, ya que no hay n√∫meros para los turnos.

Como tu y tu pareja est√°is ocupados en impedir que alguien se ponga delante y recoja tus hamburguesas cada vez que llegan, tampoco puedes prestarle atenci√≥n a tu pareja.

Este es un trabajo "s√≠ncrono", est√°s "sincronizado" con el cajero / cocinero. Tienes que esperar y estar all√≠ en el momento exacto en que el cajero / cocinero termina las hamburguesas y te las da, o de lo contrario, alguien m√°s podr√≠a cogerlas.

Luego, el cajero / cocinero finalmente regresa con sus hamburguesas, despu√©s de mucho tiempo esperando all√≠ frente al mostrador.

Cojes tus hamburguesas y vas a la mesa con tu pareja.

S√≥lo las comes y listo.

No has hablado ni coqueteado mucho, ya que has pasado la mayor parte del tiempo esperando frente al mostrador.

---

En este escenario de las hamburguesas paralelas, t√∫ eres un sistema / programa con dos procesadores (t√∫ y tu pareja), ambos esperando y dedicando su atenci√≥n a estar "esperando en el mostrador" durante mucho tiempo.

La tienda de comida r√°pida tiene 8 procesadores (cajeros / cocineros). Mientras que la tienda de hamburguesas concurrentes podr√≠a haber tenido solo 2 (un cajero y un cocinero).

Pero todo y eso, la experiencia del usuario no es la mejor.

---

Esta ser√≠a la historia paralela equivalente de las hamburguesas.

Para un ejemplo m√°s "real" de √©sto, imagina un banco.

Hasta hace poco, la mayor√≠a de los bancos ten√≠an varios cajeros y una gran l√≠nea.

Todos los cajeros haciendo todo el trabajo con un cliente tras otro.

Y tienes que esperar en la fila durante mucho tiempo o perder√°s tu turno.

Probablemente no querr√°s llevarte contigo a tu pareja a hacer recados en el banco.


###  Conclusi√≥n de la hamburguesa

En este escenario de "hamburguesas de comida r√°pida con tu pareja", debido a que hay mucha espera, tiene mucho m√°s sentido tener un sistema con concurrencia.

Este es el caso de la mayor√≠a de las aplicaciones web.

Muchos, muchos usuarios, pero el servidor est√° esperando el env√≠o de las peticiones ya que su conexi√≥n no es buena.

Y luego esperando nuevamente a que las respuestas retornen.

Esta "espera" se mide en microsegundos, pero aun as√≠, sumando todo, al final es mucha espera.

Es por eso que tiene mucho sentido usar c√≥digo as√≠ncrono para las API web.

La mayor√≠a de los framework populares de Python existentes (incluidos Flask y Django) se crearon antes de que existieran las nuevas funciones as√≠ncronas en Python. Por lo tanto, las formas en que pueden implementarse admiten la ejecuci√≥n paralela y una forma m√°s antigua de ejecuci√≥n as√≠ncrona que no es tan potente como la actual.

A pesar de que la especificaci√≥n principal para Python web as√≠ncrono (ASGI) se desarroll√≥ en Django, para agregar soporte para WebSockets.

Ese tipo de asincron√≠a es lo que hizo popular a NodeJS (aunque NodeJS no es paralelo) y esa es la fortaleza de Go como lenguaje de programaci√≥n.

Y ese es el mismo nivel de rendimiento </a> que obtienes con **FastAPI**.

Y como puede tener paralelismo y asincron√≠a al mismo tiempo, obtienes un mayor rendimiento que la mayor√≠a de los frameworks de NodeJS probados y est√° a la par con Go, que es un lenguaje compilado m√°s cercano a C <a href="https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=query&l=zijmkf-1" class="external-link" target="_blank">(all thanks to Starlette)</a>.

### Es la concurrencia mejor que el paralelismo?

No! Esa no es la moraleja de la historia.

La concurrencia es diferente al paralelismo. Y es mejor en escenarios **espec√≠ficos** que implican mucha espera. Debido a eso, generalmente es mucho mejor que el paralelismo para el desarrollo de aplicaciones web. Pero no para todo.

Entonces, para explicar eso, imagina la siguiente historia corta:

> Tienes que limpiar una casa grande y sucia.

S√≠, esa es toda la historia.

---

No hay esperas, solo hay mucho trabajo por hacer, en varios lugares de la casa.

Podr√≠a tener turnos como en el ejemplo de las hamburguesas, primero la sala de estar, luego la cocina, pero como no est√° esperando nada, solo limpiar y limpiar, los turnos no afectar√≠an nada.

Tomar√≠a la misma cantidad de tiempo terminar con o sin turnos (concurrencia) y habr√≠as hecho la misma cantidad de trabajo.

Pero en este caso, si pudieras traer a los 8 ex cajeros / cocineros / ahora limpiadores, y cada uno de ellos (y t√∫) podr√≠a tomar una zona de la casa para limpiarla, podr√≠a hacer todo el trabajo en **paralelo**, con la ayuda adicional y terminar mucho antes.

En este escenario, cada uno de los limpiadores (incluido t√∫) ser√≠a un procesador, haciendo su parte del trabajo.

Y como la mayor parte del tiempo de ejecuci√≥n lo coge el trabajo real (en lugar de esperar), y el trabajo en un sistema lo realiza una <abbr title = "Central Processing Unit"> CPU </abbr>, a estos problemas se les llama "CPU bond".

---

Ejemplos t√≠picos de operaciones dependientes de CPU son cosas que requieren un procesamiento matem√°tico complejo.

Por ejemplo:

* **Audio** o **procesamiento de im√°genes**
* **Visi√≥n por computadora**: una imagen est√° compuesta de millones de p√≠xeles, cada p√≠xel tiene 3 valores / colores, procesamiento que normalmente requiere calcular algo en esos p√≠xeles, todo al mismo tiempo.
* **Machine Learning**: normalmente requiere muchas multiplicaciones de "matriz" y "vector". Piensa en una enorme hoja de c√°lculo con n√∫meros y multipl√≠calos todos al mismo tiempo.
* **Deep Learning**: este es un subcampo de Machine Learning, por lo tanto, aplica lo mismo. Es solo que no hay una sola hoja de c√°lculo de n√∫meros para multiplicar, sino un gran conjunto de ellos, y en muchos casos, usa un procesador especial para construir y / o usar esos modelos.

### Concurrencia + Paralelismo: Web + Machine Learning 

Con **FastAPI** puedes aprovechar la concurrencia que es muy com√∫n para el desarrollo web (atractivo principal de NodeJS).

Pero tambi√©n puedes aprovechar los beneficios del paralelismo y el multiprocesamiento (tener m√∫ltiples procesos ejecut√°ndose en paralelo) para cargas de trabajo **CPU bond** como las de los sistemas de Machine Learning.

Eso, m√°s el simple hecho de que Python es el lenguaje principal para **Data Science**, Machine Learning y especialmente Deep Learning, hacen de FastAPI una muy buena combinaci√≥n para las API y aplicaciones web de Data Science / Machine Learning (entre muchas otras).

Para ver c√≥mo lograr este paralelismo en producci√≥n, consulta la secci√≥n sobre [Implementaci√≥n] (deployment.md) {. Internal-link target = _blank}.

## `async` y` await`

Las versiones modernas de python tienen una forma muy intuitiva de definir c√≥digo as√≠ncrono. Esto hace que se vea como un c√≥digo "secuencial" normal y que haga la "espera" por ti en los momentos correctos.

Cuando hay una operaci√≥n que requerir√° esperar antes de dar los resultados y tiene soporte para estas nuevas caracter√≠sticas de Python, puedes codificarlo como:

```Python
burgers = await get_burgers(2)
```


La clave aqu√≠ es la 'espera'. Le dice a Python que tiene que esperar a que `get_burgers (2)` termine de hacer lo suyo antes de almacenar los resultados en `hamburguesas`. Con eso, Python sabr√° que puede ir y hacer otra cosa mientras tanto (como recibir otra solicitud).

Para que `await` funcione, tiene que estar dentro de una funci√≥n que admita esta asincron√≠a. Para hacer eso, simplemente lo declara con `async def`:

```Python hl_lines="1"
async def get_burgers(number: int):
    # Do some asynchronous stuff to create the burgers
    return burgers
```

...instead of `def`:

```Python hl_lines="2"
# This is not asynchronous
def get_sequential_burgers(number: int):
    # Do some sequential stuff to create the burgers
    return burgers
```

Con `async def`, Python sabe que, dentro de esa funci√≥n, debe tener en cuenta las expresiones` wait ', y que puede "pausar" la ejecuci√≥n de esa funci√≥n e ir a hacer otra cosa antes de regresar.

Cuando desee llamar a una funci√≥n `async def`, debe" esperarla ". Entonces, esto no funcionar√°:

```Python
# Esto no funcionar√°, porque get_burgers se defini√≥ con: async def
hamburguesas = get_burgers (2)
```

---

Por lo tanto, si est√° utilizando una biblioteca que le dice que puede llamarla con `await`, debe crear las *funciones de enrutado* que la usan con` async def`, como en:

```Python hl_lines="2 3"
@app.get('/burgers')
async def read_burgers():
    burgers = await get_burgers(2)
    return burgers
```

### M√°s detalles t√©cnicos

Es posible que haya notado que 'esperar' solo se puede usar dentro de las funciones definidas con 'async def'.

Pero al mismo tiempo, las funciones definidas con `async def` deben ser "esperadas". Por lo tanto, las funciones con `async def` solo se pueden invocar dentro de las funciones definidas con` async def` tambi√©n.

Entonces, relacionado con la paradoja del huevo y la gallina, ¬øc√≥mo se llama a la primera funci√≥n `async`?

Si est√° trabajando con **FastAPI** no tiene que preocuparse por eso, porque esa "primera" funci√≥n ser√° su *funci√≥n de enrutados*, y FastAPI sabr√° c√≥mo hacer lo pertinente.

En el caso de que desee usar `async` /` await` sin FastAPI, <a href="https://docs.python.org/3/library/asyncio-task.html#coroutine" class="external-link" target="_blank">check the official Python docs</a>.

### Otras formas de c√≥digo as√≠ncrono

Este estilo de usar `async` y` await` es relativamente nuevo en el lenguaje.

Pero hace que trabajar con c√≥digo as√≠ncrono sea mucho m√°s f√°cil.

Esta misma sintaxis (o casi id√©ntica) tambi√©n se incluy√≥ recientemente en las versiones modernas de JavaScript (en Browser y NodeJS).

Pero antes de eso, manejar c√≥digo as√≠ncrono era bastante m√°s complejo y dif√≠cil.

En versiones anteriores de Python, podr√≠a haber utilizado hilos o <a href="http://www.gevent.org/" class="external-link" target="_blank">Gevent</a>. Pero el c√≥digo es mucho m√°s complejo de entender, depurar y desarrollar.

En versiones anteriores de NodeJS / Browser JavaScript, habr√≠a utilizado "callbacks". Lo que conduce a <a href="http://callbackhell.com/" class="external-link" target="_blank"> callback hell </a>.

## Corutinas

**Coroutine** es el t√©rmino guay para la cosa devuelta por una funci√≥n `async def`. Python sabe que es algo as√≠ como una funci√≥n que puede iniciar y que terminar√° en alg√∫n momento, pero que tambi√©n podr√≠a pausarse internamente, siempre que haya una `await` dentro de ella.

Pero toda esta funcionalidad de usar c√≥digo asincr√≥nico con `async` y` await` se resume muchas veces como el uso de "corutinas". Es comparable a la caracter√≠stica principal de Go, las "Goroutines".

## Conclusi√≥n

Veamos la misma frase de arriba:

> Las versiones modernas de Python tienen soporte para **"c√≥digo as√≠ncrono"** usando algo llamado **"corutinas"**, con la sintaxis **`async` y` await`**.

Eso ya deber√≠a tener m√°s sentido ahora.

Todo eso es lo que impulsa FastAPI (a trav√©s de Starlette) y lo que lo hace tener un rendimiento tan impresionante.

## Detalles muy t√©cnicos

!!! advertencia
¬†¬†¬†¬†Probablemente puedas saltarte esto.

    Estos son detalles muy t√©cnicos de c√≥mo **FastAPI** funciona a muy bajo nivel.
    
    Si tienes bastante conocimiento t√©cnico (corutinas, hilos, bloqueos, etc.) y tienes curiosidad acerca de c√≥mo FastAPI gestiona `async def` vs normal `def`, contin√∫a.

### Funciones de enrutado 

Cuando declara una *funci√≥n de enrutado* con `def` normal en lugar de `async def`, se ejecuta en un conjunto de subprocesos externo que luego  espera, en lugar de ser llamado directamente (ya que bloquear√≠a el servidor).

Si vienes de otro framework as√≠ncrono que no funciona de la manera descrita anteriormente y est√°s acostumbrado a definir funciones de enrutado *del tipo s√≥lo c√°lculo* con `def` simple para una peque√±a ganancia de rendimiento (aproximadamente 100 nanosegundos), tenga en cuenta que en **FastAPI** el efecto ser√≠a bastante opuesto. En estos casos, es mejor usar `async def` a menos que sus *funciones de enrutado* usen un c√≥digo que realice el bloqueo <abbr title="Input/Output: disk reading or writing, network communications.">IO</abbr>.

A√∫n as√≠, en ambas situaciones, es probable que **FastAPI** sea [a√∫n m√°s r√°pido](/#rendimiento) {.Internal-link target=_blank} que (o al menos comparable) a su framework anterior.

### Dependencias

Lo mismo se aplica para las dependencias. Si una dependencia es una funci√≥n est√°ndar `def` en lugar de `async def`, se ejecuta en el threadpool externo.

### Subdependencias

Puedes tener m√∫ltiples dependencias y subdependencias que se requieren entre s√≠ (como par√°metros de las definiciones de funci√≥n), algunas de ellas pueden crearse con `async def` y otras con `def` normal. Seguir√≠a funcionando correctamente, y los creados con `def` normal se llamar√≠an en un thread externo en lugar de ser "awaited".

### Otras "utility functions"

Cualquier otra funci√≥n de utilidad que llame directamente se puede crear con `def` o `async def` normales y FastAPI no afectar√° la manera en que la llamas.

Esto contrasta con las funciones que FastAPI llama por ti: *path operation functions* y dependencias.

Si tu utility function es una funci√≥n normal con `def`, se llamar√° directamente (tal cual la escribes en tu c√≥digo), no en un threadpool, si la funci√≥n se crea con `async def`, entonces debes usar await en esa funci√≥n cuando la llamas en tu c√≥digo.

---

Nuevamente, estos son detalles muy t√©cnicos que probablemente s√≥lo son √∫tiles si los buscas expresamente.

De lo contrario, la gu√≠a de la secci√≥n anterior deber√≠an ser suficientes: <a href="#in-a-hurry">In a hurry?</a>.
